import openai
from tqdm import tqdm

from evaluation.tasks.generation.wildbench.fastchat_conversation import HF_Conversation, map_to_conv

OPENAI_RATE_LIMIT_ERROR = openai.RateLimitError
OPENAI_API_ERROR = openai.APIError


def apply_template(chat_history, model_name, args):
    model_inputs = []
    conv = None
    for chats in tqdm(chat_history, desc="Applying template", disable=True):
        if args.engine not in ["vllm", "hf"]:
            model_inputs.append("n/a")  # will be handled by another ways.
            continue
        else:
            if conv is None or isinstance(conv, HF_Conversation) == False:
                conv = map_to_conv(model_name)
            else:
                conv.clear()
        for chat_id, chat in enumerate(chats):
            conv.append_message(conv.roles[chat_id % 2], chat)
        conv.append_message(conv.roles[1], None)
        model_inputs.append(conv.get_prompt())
    return model_inputs

