import json
import multiprocessing as mp
import os

import fire
import torch

from evaluation.utils import maybe_merge_lora_weights_and_save


def run(gpu_queue, script_format: str, task_name: str):
    gpu_id = gpu_queue.get()
    print(f"Running {task_name} on GPU {gpu_id}.")
    command = script_format.format(gpu_id=gpu_id, task_name=task_name)
    os.system(command)
    gpu_queue.put(gpu_id)


def main(
        model_name_or_path: str,
        model_input_template_path_or_name: str,
        report_output_path: str,
        save_individual_results_path: str,
        filter_classifier_name: str | None = None,
        filter_model_override_path: str | None = None,
):
    entrypoint_script_path = os.path.join(
        os.path.abspath(os.path.dirname(__file__)), "eval.py"
    )
    mp.set_start_method("spawn", force=True)
    # turn model_name_or_path to abspath if it is a relative path.

    if os.path.exists(model_name_or_path):
        model_name_or_path = os.path.abspath(model_name_or_path)

    temp_dir_for_merged_weights = maybe_merge_lora_weights_and_save(model_name_or_path)
    if temp_dir_for_merged_weights is not None:
        model_name_or_path = temp_dir_for_merged_weights

    # here, we assume that we use vllm.
    task_names = [
        "mtbench",
        "alpacaeval",
        "harmbench",
        "toxigen:tiny",
        "xstest",
        "wildguardtest",
        "wildjailbreak:benign",
        "wildjailbreak:harmful",
        "do_anything_now",
        "trustllm_jailbreaktrigger",
        "codex_eval",
        "gsm8k:8shot_cot",
        "bbh:cot",
        "wildbench",
    ]

    task_names_no_vllm_support = [
        "mmlu",
        "truthfulqa",
    ]

    # you can run in parallel.
    num_devices = torch.cuda.device_count()
    print(f"Number of devices: {num_devices}")

    with mp.Manager() as manager:
        gpu_queue = manager.Queue()
        for i in range(num_devices):
            gpu_queue.put(i)

        with mp.Pool(processes=num_devices) as pool:
            res = []
            script_format = (
                "CUDA_VISIBLE_DEVICES={gpu_id} \\\n"
                f"python {entrypoint_script_path} generators \\\n"
                f"  --model_name_or_path {model_name_or_path} \\\n"
                f"  --model_input_template_path_or_name {model_input_template_path_or_name} \\\n"
                "   --tasks {task_name} \\\n"
                f"  --report_output_path {report_output_path}" ".{task_name} \\\n"
                f"  --save_individual_results_path {save_individual_results_path}" ".{task_name} \\\n"
                "   --use_vllm \\\n"
                f"  --filter_classifier_name {filter_classifier_name} \\\n"
                f"  --filter_model_override_path {filter_model_override_path}"
            )
            script_format_no_vllm = (
                "CUDA_VISIBLE_DEVICES={gpu_id} \\\n"
                f"python {entrypoint_script_path} generators \\\n"
                f"  --model_name_or_path {model_name_or_path} \\\n"
                f"  --model_input_template_path_or_name {model_input_template_path_or_name} \\\n"
                "   --tasks {task_name} \\\n"
                "   --batch_size 8 \\\n"
                f"  --report_output_path {report_output_path}" ".{task_name} \\\n"
                f"  --save_individual_results_path {save_individual_results_path}" ".{task_name} \\\n"
                f"  --filter_classifier_name {filter_classifier_name} \\\n"
                f"  --filter_model_override_path {filter_model_override_path}"
            )
            for task_name in task_names:
                res.append(pool.apply_async(run, (gpu_queue, script_format, task_name)))

            for task_name in task_names_no_vllm_support:
                res.append(pool.apply_async(run, (gpu_queue, script_format_no_vllm, task_name)))

            for task_name, r in zip(task_names, res):
                try:
                    r.get()
                except Exception as e:
                    print(f"Error in {task_name}.")
                    print(e)

            # wait for all processes to finish.
            pool.close()
            pool.join()

    # load all reports and merge them.
    report_files = [report_output_path + f".{task_name}" for task_name in task_names] + \
                   [report_output_path + f".{task_name}" for task_name in task_names_no_vllm_support]
    save_files = [save_individual_results_path + f".{task_name}" for task_name in task_names] + \
                 [save_individual_results_path + f".{task_name}" for task_name in task_names_no_vllm_support]

    # merge reports.
    all_report = {}
    for report_file in report_files:
        try:
            with open(report_file, "r") as f:
                report = json.load(f)
                all_report.update(report)
        except FileNotFoundError:
            print(f"Report file {report_file} not found.")

    with open(report_output_path, "w") as f:
        json.dump(all_report, f)

    # merge save files.
    all_save = []
    for save_file in save_files:
        try:
            with open(save_file, "r") as f:
                save = json.load(f)
                all_save.extend(save)
        except FileNotFoundError:
            print(f"Save file {save_file} not found.")

    with open(save_individual_results_path, "w") as f:
        json.dump(all_save, f)

    if temp_dir_for_merged_weights is not None:
        print(f"Removing temporary directory: {temp_dir_for_merged_weights}")
        os.system(f"rm -rf {temp_dir_for_merged_weights}")


if __name__ == "__main__":
    fire.Fire(main)
